# ğŸ¤Ÿ ASL Translator Mobile App

A mobile application for **American Sign Language (ASL) alphabet recognition** with **on-device AI inference**. Captures a photo of an ASL hand sign and instantly predicts the letter using MediaPipe + TensorFlow Lite running entirely on your phone.

## âœ¨ Key Features

- ğŸ“± **On-Device Inference** â€” No internet required, works offline
- âš¡ **Fast** â€” <100ms prediction time
- ğŸ”’ **Private** â€” Images never leave your device
- ğŸ¯ **99.38% Accuracy** â€” Advanced landmark-based AI model
- ğŸ“· **Camera & Gallery** â€” Capture or select images

## ğŸš€ Quick Start

### Prerequisites

- Node.js (LTS)
- Java JDK 17 (Temurin or Oracle)
- Android Studio (SDK, NDK, CMake)
- Physical Android device or emulator (API 26+)

## ğŸ§° Installation Guide (Windows)

Follow these steps to set up your environment on Windows for building and running the app.

### 1) Install Node.js (LTS)

- Download and install from https://nodejs.org
- Verify:

```powershell
node -v
npm -v
```

### 2) Install Java JDK 17

- Recommended: Eclipse Temurin (OpenJDK) 17 from https://adoptium.net
- Alternatively, Oracle JDK 17 from https://www.oracle.com/java/technologies/downloads/
- Verify:

```powershell
java -version
```

Set JAVA_HOME (adjust the path to your JDK install):

```powershell
# Example path - update if different on your machine
setx JAVA_HOME "C:\\Program Files\\Eclipse Adoptium\\jdk-17"
setx PATH "%PATH%;%JAVA_HOME%\\bin"
```

### 3) Install Android Studio

- Download from https://developer.android.com/studio and complete installation
- Launch Android Studio once to initialize the SDK

Install SDK/NDK/CMake via Settings:

1. Android Studio â†’ Settings â†’ Appearance & Behavior â†’ System Settings â†’ Android SDK
2. Tab â€œSDK Platformsâ€: install latest Android API (API 26+ supported; latest recommended i.e. Android 16.0 ("Baklava"))
3. Tab â€œSDK Toolsâ€: check and install:
	- Android SDK Build-Tools
	- NDK (Side by side)
	- Android SDK Command-line Tools (latest)
	- CMake
    - Android Emulator
    - Android Emulator Hypervisor Driver (installer)
	- Android SDK Platform-Tools

Default SDK path (for ANDROID_HOME):

- C:\\Users\\<YourUser>\\AppData\\Local\\Android\\Sdk

Set ANDROID_HOME and add tools to PATH:

```powershell
setx ANDROID_HOME "%USERPROFILE%\\AppData\\Local\\Android\\Sdk"
setx PATH "%PATH%;%ANDROID_HOME%\\platform-tools;%ANDROID_HOME%\\cmdline-tools\\latest\\bin"
```

### 4) Set up an Emulator or Device

- Emulator: Android Studio â†’ More Actions â†’ Virtual Device Manager â†’  Create Virtual Device (+ button on top) â†’ choose a device (i.e. Pixel 6) + next â†’ Download (name and finish)  â†’ Click start on right side of device name (and wait till it starts)
- Physical device: Enable Developer Options + USB Debugging; connect via USB and accept the debug prompt
- Verify device visibility:

```powershell
adb devices
```

### 5) Install project dependencies

```powershell
cd mobile/asl-expo
npm install
```

### 6) Build and Run on Android
make sure to have internet connection on first build & also it required to run the emulator and start mobile from android studio before starting app (and if you are using mobile make sure its unlocked & usb debugging is turned on)
```powershell
cd mobile/asl-expo
npx expo run:android
```

Build APK without running:

```powershell
cd mobile/asl-expo/android
./gradlew.bat :app:assembleDebug
# Output: android/app/build/outputs/apk/debug/app-debug.apk
```

### Troubleshooting

- Gradle JDK mismatch: Use JDK 17. In Android Studio, set Project Settings â†’ Gradle JDK to your JDK 17 install.
- Missing NDK/CMake: Revisit Settings â†’ Android SDK â†’ SDK Tools and install NDK (Side by side) and CMake.
- Device not detected: Install OEM drivers; run `adb kill-server` then `adb start-server`; ensure USB debugging enabled.
- Permissions error on Windows: Run terminal as Administrator for initial environment variable setup.

### Run the App

```bash
# Navigate to mobile app
cd mobile/asl-expo

# Install dependencies
npm install

# Run on Android (builds APK and launches)
npx expo run:android
```

### Build APK Only

```bash
cd mobile/asl-expo/android
./gradlew.bat :app:assembleDebug
# Output: android/app/build/outputs/apk/debug/app-debug.apk
```

## ğŸ“± How It Works

1. **Capture** â€” Take a photo of your hand sign or select from gallery
2. **Detect** â€” MediaPipe finds and tracks 21 hand landmarks
3. **Classify** â€” TensorFlow Lite model predicts the ASL letter
4. **Display** â€” Result shown instantly on screen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ON-DEVICE INFERENCE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Photo â†’ MediaPipe â†’ 21 Landmarks â†’ TFLite â†’ ASL Letter (A-Z)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
NewASL-App/
â”œâ”€â”€ mobile/
â”‚   â””â”€â”€ asl-expo/                    # React Native + Expo app
â”‚       â”œâ”€â”€ screens/                 # UI screens
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ config/             # Inference mode config
â”‚       â”‚   â””â”€â”€ inference/          # Prediction logic
â”‚       â””â”€â”€ android/                # Native Android code
â”‚           â””â”€â”€ app/src/main/
â”‚               â”œâ”€â”€ java/.../mediapipe/  # Kotlin native module
â”‚               â””â”€â”€ assets/              # AI models
â”‚                   â”œâ”€â”€ hand_landmarker.task
â”‚                   â”œâ”€â”€ asl_landmark_model.tflite
â”‚                   â””â”€â”€ asl_landmark_model.txt
â”œâ”€â”€ documentation/                   # Full documentation
â””â”€â”€ REACT_NATIVE_GUIDE.md           # Development guide
```

## ğŸ“š Documentation

- [Migration Documentation](documentation/MIGRATION_SIGN_LANGUAGE_TO_ASL_EXPO.md) â€” Why this architecture
- [Technical Details](documentation/mobile-ondevice-inference/03_TECHNICAL_ONDEVICE_INFERENCE.md)
- [Client Sharing Guide](documentation/mobile-ondevice-inference/01_CLIENT_SHARING_GUIDE_WITH_SOURCE.md)
- [React Native Guide](REACT_NATIVE_GUIDE.md)

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Framework | React Native + Expo |
| Navigation | React Navigation |
| AI Detection | MediaPipe Tasks Vision |
| AI Classification | TensorFlow Lite |
| Native Code | Kotlin (Android) |
| Min Android | API 26 (Android 8.0) |

## ğŸ“ Notes

- **Expo Go not supported** â€” Requires native code for MediaPipe/TFLite
- **Android only** â€” iOS native module not yet implemented
- **Still images only** â€” Real-time video inference not implemented

---

*Built with MediaPipe and TensorFlow Lite for on-device AI*
