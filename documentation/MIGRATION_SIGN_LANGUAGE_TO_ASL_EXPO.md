# Migration Documentation: Sign-Language-Translator â†’ asl-expo

This document details the complete migration from the original **Sign-Language-Translator-project** to the new **asl-expo** mobile application, including what changed, what stayed the same, and the critical reasons behind the transition away from Expo Go.

---

## ğŸ“‹ Executive Summary

| Aspect | Old: Sign-Language-Translator | New: asl-expo |
|--------|------------------------------|---------------|
| **Project Status** | Incomplete (screens only) | Complete runnable app |
| **Runtime** | Expo Go dependent | Expo Dev Build (custom native code) |
| **Inference** | Backend-only (network required) | On-device + Backend fallback |
| **Model** | Remote server processing | Bundled TFLite (25.5 KB) |
| **Hand Detection** | Server-side MediaPipe | On-device MediaPipe Tasks |
| **Offline Capability** | âŒ No | âœ… Yes |
| **Build Output** | N/A (no build config) | Android APK |

---

## ğŸ”„ What Stayed the Same

### 1. Screen Components & UI/UX
All original screen files were preserved with **identical UI/UX**:

| Screen | Purpose | Changes |
|--------|---------|---------|
| `HomeScreen.js` | Main landing page | None |
| `LoginScreen.js` | User authentication | None |
| `SignupScreen.js` | User registration | None |
| `SignToTextScreen.js` | ASL â†’ Text translation | Inference routing only |
| `TextToSignScreen.js` | Text â†’ ASL animation | None |
| `AlphabetScreen.js` | ASL alphabet reference | None |
| `NumberScreen.js` | ASL numbers reference | None |
| `SignLibraryScreen.js` | Sign library browser | None |
| `HistoryScreen.js` | Translation history | None |
| `AboutScreen.js` | App information | None |
| `SplashScreen.js` | App loading screen | None |
| `forgotscreen.js` | Password recovery | None |

### 2. Firebase Integration
- `firebaseConfig.js` â€” Firebase configuration preserved identically
- Authentication flow unchanged

### 3. Core Dependencies
- `expo-image-picker` â€” Camera/Gallery image selection
- `@react-navigation/native` â€” Navigation structure
- `axios` â€” HTTP client for backend fallback
- `formik` + `yup` â€” Form handling and validation

### 4. Visual Design
- Color scheme (`#1F3A93` primary blue)
- Typography and styling
- Component layouts and interactions
- Theme context system (`ThemeContext.js`)

---

## â¬†ï¸ What Was Upgraded

### 1. Project Structure

**Before (Sign-Language-Translator-project):**
```
Sign-Language-Translator-project/
â”œâ”€â”€ AboutScreen.js
â”œâ”€â”€ AlphabetScreen.js
â”œâ”€â”€ HomeScreen.js
â”œâ”€â”€ LoginScreen.js
â”œâ”€â”€ SignToTextScreen.js
â”œâ”€â”€ ... (other screens)
â”œâ”€â”€ firebaseConfig.js
â””â”€â”€ main.py              # Backend server
```
- âŒ No `package.json`
- âŒ No Expo/React Native configuration
- âŒ No Android native project
- âŒ No build capability

**After (asl-expo):**
```
asl-expo/
â”œâ”€â”€ App.js                           # Navigation wiring
â”œâ”€â”€ ThemeContext.js                  # Theme provider
â”œâ”€â”€ package.json                     # Dependencies
â”œâ”€â”€ app.json                         # Expo configuration
â”œâ”€â”€ index.js                         # Entry point
â”œâ”€â”€ screens/                         # All screen components
â”‚   â””â”€â”€ (14 screens)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ inferenceConfig.js       # Backend vs on-device toggle
â”‚   â””â”€â”€ inference/
â”‚       â””â”€â”€ predictSignFromImageUri.js # Unified inference entry
â””â”€â”€ android/                         # Full native Android project
    â””â”€â”€ app/
        â””â”€â”€ src/main/
            â”œâ”€â”€ java/.../mediapipe/
            â”‚   â”œâ”€â”€ SignPredictorModule.kt    # Native inference module
            â”‚   â””â”€â”€ SignPredictorPackage.kt   # Package registration
            â””â”€â”€ assets/
                â”œâ”€â”€ hand_landmarker.task      # MediaPipe model
                â”œâ”€â”€ asl_landmark_model.tflite # TFLite classifier
                â””â”€â”€ asl_landmark_model.txt    # Label mapping
```

### 2. Inference Architecture

**Before:** Backend-Dependent API Call
```javascript
// Old approach - required server running
const axiosResponse = await axios.post(
  "http://192.168.1.14:7000/predict",
  formData,
  { headers: { "Content-Type": "multipart/form-data" } }
);
```
- âš ï¸ Required backend server running
- âš ï¸ Required network connectivity
- âš ï¸ Hardcoded IP address
- âš ï¸ Latency dependent on network

**After:** On-Device with Backend Fallback
```javascript
// New approach - on-device first, backend fallback
import { INFERENCE_MODE, BACKEND_PREDICT_URL } from '../config/inferenceConfig';

if (INFERENCE_MODE === 'mediapipe') {
  // On-device inference via native module
  const label = await NativeModules.SignPredictor.predictFromImageUri(imageUri);
} else {
  // Backend fallback if needed
  const response = await fetch(BACKEND_PREDICT_URL, ...);
}
```

### 3. Native Module Integration

Added Kotlin native module `SignPredictorModule` that:
1. Resolves image URI from camera/gallery
2. Decodes bitmap with EXIF orientation correction
3. Runs MediaPipe HandLandmarker (IMAGE mode)
4. Extracts 21 landmarks Ã— 3 coordinates = 63 features
5. Normalizes features (wrist-relative, scale-invariant)
6. Runs TFLite classifier inference
7. Returns predicted ASL letter

### 4. Build Configuration

| Configuration | Value | Reason |
|---------------|-------|--------|
| `minSdkVersion` | 26 (Android 8.0+) | MediaPipe Tasks requires Java MethodHandle APIs |
| Expo SDK | 54 | Latest stable with dev build support |
| React Native | 0.81.5 | Compatible with Expo SDK 54 |

---

## ğŸš« Why We're NOT Using Expo Go Anymore

### The Core Problem

**Expo Go** is a pre-built app that runs JavaScript code, but it has a **fixed set of native modules**. It cannot run:
- Custom native code (Kotlin/Swift)
- Native libraries not included in Expo SDK
- MediaPipe Tasks Vision
- TensorFlow Lite runtime

### Why MediaPipe Requires Native Code

Our ASL translator uses a **multi-stage inference pipeline**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ASL TRANSLATION PIPELINE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Image â†’ MediaPipe HandLandmarker â†’ 21 Landmarks â†’ TFLite â†’ ASL â”‚
â”‚         (Native C++ library)        (63 floats)   (Native)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **MediaPipe HandLandmarker** â€” Google's hand detection model is a native C++ library with platform-specific binaries
- **TensorFlow Lite** â€” The inference runtime is also native C/C++ for performance
- **On-device ML** â€” Both require access to hardware acceleration (GPU/NPU) via native APIs

### Why Other Approaches Failed

| Approach | Why It Didn't Work |
|----------|-------------------|
| `react-native-mediapipe` | Pulls in camera/video stacks; caused Windows build failures; designed for real-time video, not still images |
| `expo-tensorflow` | No longer maintained; doesn't support custom models |
| WebAssembly MediaPipe | Too slow for mobile; no hardware acceleration |
| Backend-only | Required server running; network latency; no offline support |

### The Solution: Expo Dev Builds

**Expo Dev Builds** allow us to:
1. âœ… Write custom native modules (Kotlin for Android)
2. âœ… Include MediaPipe Tasks Vision library
3. âœ… Bundle TFLite models in APK
4. âœ… Run inference entirely on-device
5. âœ… Still use Expo's managed workflow for JS development

**Build Process Change:**
```bash
# OLD: Expo Go (no build needed, but limited)
npx expo start
# â†’ Scan QR with Expo Go app

# NEW: Dev Build (full native capability)
npx expo run:android
# â†’ Builds actual APK with native code
```

---

## ğŸ¤– TensorFlow + MediaPipe Integration Details

### Model Assets Bundled in APK

| File | Size | Purpose |
|------|------|---------|
| `hand_landmarker.task` | ~5 MB | MediaPipe Tasks hand detection model |
| `asl_landmark_model.tflite` | 25.5 KB | Custom ASL letter classifier |
| `asl_landmark_model.txt` | ~200 B | Class label mapping (A-Z, del, space) |

### Inference Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ON-DEVICE INFERENCE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  1. IMAGE INPUT                                                          â”‚
â”‚     â”œâ”€ Camera capture (via expo-image-picker)                           â”‚
â”‚     â””â”€ Gallery selection (via expo-image-picker)                        â”‚
â”‚                                                                          â”‚
â”‚  2. MEDIAPIPE HANDLANDMARKER                                            â”‚
â”‚     â”œâ”€ Detects hand in image                                            â”‚
â”‚     â”œâ”€ Extracts 21 landmark points                                      â”‚
â”‚     â””â”€ Returns (x, y, z) for each â†’ 63 float values                    â”‚
â”‚                                                                          â”‚
â”‚  3. FEATURE NORMALIZATION                                                â”‚
â”‚     â”œâ”€ Translate to wrist-relative coordinates                          â”‚
â”‚     â”œâ”€ Scale to unit size (hand size invariant)                         â”‚
â”‚     â””â”€ Produces normalized 63-float feature vector                      â”‚
â”‚                                                                          â”‚
â”‚  4. TFLITE CLASSIFIER                                                    â”‚
â”‚     â”œâ”€ Input: 63 normalized floats                                      â”‚
â”‚     â”œâ”€ Architecture: Dense(128) â†’ Dense(64) â†’ Dense(32) â†’ Dense(28)    â”‚
â”‚     â”œâ”€ Output: 28 class probabilities                                   â”‚
â”‚     â””â”€ Returns highest probability class                                 â”‚
â”‚                                                                          â”‚
â”‚  5. RESULT                                                               â”‚
â”‚     â””â”€ ASL letter (A-Z) or special (del, space)                         â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Comparison

| Metric | Backend (Old) | On-Device (New) |
|--------|---------------|-----------------|
| Latency | 200-500ms (network dependent) | <100ms |
| Offline | âŒ No | âœ… Yes |
| Privacy | âš ï¸ Images sent to server | âœ… All local |
| Battery | Higher (network + server wait) | Lower |
| Reliability | âš ï¸ Server must be running | âœ… Always works |

---

## ğŸ“± Build & Deployment Changes

### Development Requirements

| Requirement | Status |
|-------------|--------|
| Node.js LTS | Required |
| Android Studio | Required for dev builds |
| Android SDK | Required |
| JDK | Required (bundled with Android Studio) |
| NDK | Required for some native dependencies |

### Build Commands

```bash
# Navigate to mobile app
cd mobile/asl-expo

# Install dependencies
npm install

# Build and run on connected device/emulator
npx expo run:android

# Or build APK directly
cd android
./gradlew.bat :app:assembleDebug
# Output: android/app/build/outputs/apk/debug/app-debug.apk
```

### Configuration Files Added

| File | Purpose |
|------|---------|
| `app.json` | Expo configuration with build properties |
| `android/app/build.gradle` | Android build configuration (minSdk 26) |
| `src/config/inferenceConfig.js` | Toggle between backend/on-device modes |

---

## âš™ï¸ Switching Between Inference Modes

The app supports both modes for flexibility:

```javascript
// src/config/inferenceConfig.js

// Use 'mediapipe' for on-device inference (default)
// Use 'backend' for server-side inference
export const INFERENCE_MODE = 'mediapipe';

// Backend URL (only used if INFERENCE_MODE === 'backend')
export const BACKEND_PREDICT_URL = 'http://192.168.1.14:7000/predict';
```

---

## ğŸ“ Summary of Changes

| Category | What Changed | Why |
|----------|-------------|-----|
| **Project Structure** | Added complete Expo + Android project | Original had no runnable scaffold |
| **Build System** | Expo Dev Builds instead of Expo Go | Need custom native modules for ML |
| **Inference** | On-device MediaPipe + TFLite | Offline capability, lower latency, privacy |
| **Native Code** | Added Kotlin SignPredictor module | Interface between React Native and native ML |
| **Models** | Bundled in APK assets | On-device inference requirement |
| **SDK Version** | minSdkVersion 26 | MediaPipe dependency requirement |
| **Dependencies** | Added expo-build-properties | Configure native build settings |

---

## ğŸ“š Related Documentation

- [Technical On-Device Inference Details](mobile-ondevice-inference/03_TECHNICAL_ONDEVICE_INFERENCE.md)
- [Implementation Log](mobile-ondevice-inference/05_IMPLEMENTATION_LOG.md)
- [Changes from Original Handoff](mobile-ondevice-inference/06_CHANGES_FROM_ORIGINAL_HANDOFF.md)
- [Client Sharing Guide](mobile-ondevice-inference/01_CLIENT_SHARING_GUIDE_WITH_SOURCE.md)

---

*Last updated: 2025-12-18*
