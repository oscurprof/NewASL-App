# ðŸ¤Ÿ ASL Translator Mobile App

A mobile application for **American Sign Language (ASL) alphabet recognition** with **on-device AI inference**. Captures a photo of an ASL hand sign and instantly predicts the letter using MediaPipe + TensorFlow Lite running entirely on your phone.

## âœ¨ Key Features

- ðŸ“± **On-Device Inference** â€” No internet required, works offline
- âš¡ **Fast** â€” <100ms prediction time
- ðŸ”’ **Private** â€” Images never leave your device
- ðŸŽ¯ **99.38% Accuracy** â€” Advanced landmark-based AI model
- ðŸ“· **Camera & Gallery** â€” Capture or select images

## ðŸš€ Quick Start

### Prerequisites

- [Node.js](https://nodejs.org/) LTS
- [Android Studio](https://developer.android.com/studio) with SDK
- Physical Android device or emulator (API 26+)

### Run the App

```bash
# Navigate to mobile app
cd mobile/asl-expo

# Install dependencies
npm install

# Run on Android (builds APK and launches)
npx expo run:android
```

### Build APK Only

```bash
cd mobile/asl-expo/android
./gradlew.bat :app:assembleDebug
# Output: android/app/build/outputs/apk/debug/app-debug.apk
```

## ðŸ“± How It Works

1. **Capture** â€” Take a photo of your hand sign or select from gallery
2. **Detect** â€” MediaPipe finds and tracks 21 hand landmarks
3. **Classify** â€” TensorFlow Lite model predicts the ASL letter
4. **Display** â€” Result shown instantly on screen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ON-DEVICE INFERENCE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Photo â†’ MediaPipe â†’ 21 Landmarks â†’ TFLite â†’ ASL Letter (A-Z)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“ Project Structure

```
NewASL-App/
â”œâ”€â”€ mobile/
â”‚   â””â”€â”€ asl-expo/                    # React Native + Expo app
â”‚       â”œâ”€â”€ screens/                 # UI screens
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ config/             # Inference mode config
â”‚       â”‚   â””â”€â”€ inference/          # Prediction logic
â”‚       â””â”€â”€ android/                # Native Android code
â”‚           â””â”€â”€ app/src/main/
â”‚               â”œâ”€â”€ java/.../mediapipe/  # Kotlin native module
â”‚               â””â”€â”€ assets/              # AI models
â”‚                   â”œâ”€â”€ hand_landmarker.task
â”‚                   â”œâ”€â”€ asl_landmark_model.tflite
â”‚                   â””â”€â”€ asl_landmark_model.txt
â”œâ”€â”€ documentation/                   # Full documentation
â””â”€â”€ REACT_NATIVE_GUIDE.md           # Development guide
```

## ðŸ“š Documentation

- [Migration Documentation](documentation/MIGRATION_SIGN_LANGUAGE_TO_ASL_EXPO.md) â€” Why this architecture
- [Technical Details](documentation/mobile-ondevice-inference/03_TECHNICAL_ONDEVICE_INFERENCE.md)
- [Client Sharing Guide](documentation/mobile-ondevice-inference/01_CLIENT_SHARING_GUIDE_WITH_SOURCE.md)
- [React Native Guide](REACT_NATIVE_GUIDE.md)

## ðŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Framework | React Native + Expo |
| Navigation | React Navigation |
| AI Detection | MediaPipe Tasks Vision |
| AI Classification | TensorFlow Lite |
| Native Code | Kotlin (Android) |
| Min Android | API 26 (Android 8.0) |

## ðŸ“ Notes

- **Expo Go not supported** â€” Requires native code for MediaPipe/TFLite
- **Android only** â€” iOS native module not yet implemented
- **Still images only** â€” Real-time video inference not implemented

---

*Built with MediaPipe and TensorFlow Lite for on-device AI*
